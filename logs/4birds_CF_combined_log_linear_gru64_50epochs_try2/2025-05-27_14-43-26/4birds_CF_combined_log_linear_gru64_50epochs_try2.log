[2025-05-27 14:43:26,088][__main__][INFO] - Experiment: 4birds_CF_combined_log_linear_gru64_50epochs_try2
[2025-05-27 14:43:26,138][__main__][INFO] - Using device: cuda
[2025-05-27 14:43:26,138][__main__][INFO] - Checking for datasets...
[2025-05-27 14:43:26,139][__main__][INFO] - ESC-50 dataset found at: ESC-50-master
[2025-05-27 14:43:26,139][__main__][INFO] - Creating initial bird sound datasets (train/val/test)...
[2025-05-27 14:43:26,139][__main__][INFO] - Using dataset split parameters: val=0.15, test=0.15, seed=42
[2025-05-27 14:43:26,232][__main__][INFO] - Initial bird samples: Train=6996, Val=1495, Test=1495
[2025-05-27 14:43:26,232][__main__][INFO] - Calculating target number of 'no birds' samples...
[2025-05-27 14:43:26,232][__main__][INFO] - Number of bird classes: 8. 'No Birds' label index: 8
[2025-05-27 14:43:26,234][__main__][INFO] - Average samples per bird class in training set: 874.50
[2025-05-27 14:43:26,234][__main__][INFO] - Target 'no birds' samples for training: 874
[2025-05-27 14:43:26,234][__main__][INFO] - Target 'no birds' samples for validation: 187
[2025-05-27 14:43:26,234][__main__][INFO] - Target 'no birds' samples for testing: 187
[2025-05-27 14:43:26,254][__main__][INFO] - Combining bird and 'no birds' datasets...
[2025-05-27 14:43:26,255][__main__][INFO] - Final training samples: 7832
[2025-05-27 14:43:26,255][__main__][INFO] - Final validation samples: 1682
[2025-05-27 14:43:26,255][__main__][INFO] - Final testing samples: 1682
[2025-05-27 14:43:26,428][__main__][INFO] - Using specific LR for breakpoint parameters: 3.0.
[2025-05-27 14:43:26,428][__main__][INFO] - Using specific LR for transition_width parameters: 0.1.
[2025-05-27 14:43:27,663][__main__][INFO] - Model architecture:
[2025-05-27 14:43:27,665][__main__][INFO] - Improved_Phi_GRU_ATT(
  (combined_log_linear_spec): DifferentiableSpectrogram()
  (amplitude_to_db): AmplitudeToDB()
  (phi): MatchboxNetSkip(
    (initial_conv_module): Sequential(
      (0): PhiNetCausalConvBlock(
        (_layers): ModuleList(
          (0): CausalConv1d(
            (pad): ConstantPad1d(padding=(0, 0), value=0)
            (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)
          )
          (1): BatchNorm1d(64, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)
          (2): Hardswish()
          (3): Dropout1d(p=0.05, inplace=False)
          (4): DepthwiseCausalConv(
            (pad): ConstantPad1d(padding=(4, 0), value=0)
            (conv): Conv1d(64, 64, kernel_size=(5,), stride=(1,), groups=64, bias=False)
          )
          (5): BatchNorm1d(64, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)
          (6): Hardswish()
          (7): SEBlock(
            (se_conv): CausalConv1d(
              (pad): ConstantPad1d(padding=(0, 0), value=0)
              (conv): Conv1d(64, 10, kernel_size=(1,), stride=(1,), bias=False)
            )
            (se_conv2): CausalConv1d(
              (pad): ConstantPad1d(padding=(0, 0), value=0)
              (conv): Conv1d(10, 64, kernel_size=(1,), stride=(1,), bias=False)
            )
            (activation): Hardswish()
            (mult): FloatFunctional(
              (activation_post_process): Identity()
            )
          )
          (8): CausalConv1d(
            (pad): ConstantPad1d(padding=(0, 0), value=0)
            (conv): Conv1d(64, 32, kernel_size=(1,), stride=(1,), bias=False)
          )
          (9): BatchNorm1d(32, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)
        )
      )
      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.3, inplace=False)
    )
    (blocks_modulelist): ModuleList(
      (0): ModuleList(
        (0): Sequential(
          (0): PhiNetCausalConvBlock(
            (_layers): ModuleList(
              (0): CausalConv1d(
                (pad): ConstantPad1d(padding=(0, 0), value=0)
                (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)
              )
              (1): BatchNorm1d(32, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)
              (2): Hardswish()
              (3): Dropout1d(p=0.05, inplace=False)
              (4): DepthwiseCausalConv(
                (pad): ConstantPad1d(padding=(2, 0), value=0)
                (conv): Conv1d(32, 32, kernel_size=(3,), stride=(1,), groups=32, bias=False)
              )
              (5): BatchNorm1d(32, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)
              (6): Hardswish()
              (7): SEBlock(
                (se_conv): CausalConv1d(
                  (pad): ConstantPad1d(padding=(0, 0), value=0)
                  (conv): Conv1d(32, 5, kernel_size=(1,), stride=(1,), bias=False)
                )
                (se_conv2): CausalConv1d(
                  (pad): ConstantPad1d(padding=(0, 0), value=0)
                  (conv): Conv1d(5, 32, kernel_size=(1,), stride=(1,), bias=False)
                )
                (activation): Hardswish()
                (mult): FloatFunctional(
                  (activation_post_process): Identity()
                )
              )
              (8): CausalConv1d(
                (pad): ConstantPad1d(padding=(0, 0), value=0)
                (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)
              )
              (9): BatchNorm1d(32, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)
            )
            (op): FloatFunctional(
              (activation_post_process): Identity()
            )
          )
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Dropout(p=0.3, inplace=False)
        )
        (1): Sequential(
          (0): PhiNetCausalConvBlock(
            (_layers): ModuleList(
              (0): CausalConv1d(
                (pad): ConstantPad1d(padding=(0, 0), value=0)
                (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)
              )
              (1): BatchNorm1d(32, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)
              (2): Hardswish()
              (3): Dropout1d(p=0.05, inplace=False)
              (4): DepthwiseCausalConv(
                (pad): ConstantPad1d(padding=(4, 0), value=0)
                (conv): Conv1d(32, 32, kernel_size=(3,), stride=(1,), dilation=(2,), groups=32, bias=False)
              )
              (5): BatchNorm1d(32, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)
              (6): Hardswish()
              (7): SEBlock(
                (se_conv): CausalConv1d(
                  (pad): ConstantPad1d(padding=(0, 0), value=0)
                  (conv): Conv1d(32, 5, kernel_size=(1,), stride=(1,), bias=False)
                )
                (se_conv2): CausalConv1d(
                  (pad): ConstantPad1d(padding=(0, 0), value=0)
                  (conv): Conv1d(5, 32, kernel_size=(1,), stride=(1,), bias=False)
                )
                (activation): Hardswish()
                (mult): FloatFunctional(
                  (activation_post_process): Identity()
                )
              )
              (8): CausalConv1d(
                (pad): ConstantPad1d(padding=(0, 0), value=0)
                (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)
              )
              (9): BatchNorm1d(32, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)
            )
            (op): FloatFunctional(
              (activation_post_process): Identity()
            )
          )
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Dropout(p=0.3, inplace=False)
        )
      )
      (1): ModuleList(
        (0): Sequential(
          (0): PhiNetCausalConvBlock(
            (_layers): ModuleList(
              (0): CausalConv1d(
                (pad): ConstantPad1d(padding=(0, 0), value=0)
                (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)
              )
              (1): BatchNorm1d(32, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)
              (2): Hardswish()
              (3): Dropout1d(p=0.05, inplace=False)
              (4): DepthwiseCausalConv(
                (pad): ConstantPad1d(padding=(8, 0), value=0)
                (conv): Conv1d(32, 32, kernel_size=(3,), stride=(1,), dilation=(4,), groups=32, bias=False)
              )
              (5): BatchNorm1d(32, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)
              (6): Hardswish()
              (7): SEBlock(
                (se_conv): CausalConv1d(
                  (pad): ConstantPad1d(padding=(0, 0), value=0)
                  (conv): Conv1d(32, 5, kernel_size=(1,), stride=(1,), bias=False)
                )
                (se_conv2): CausalConv1d(
                  (pad): ConstantPad1d(padding=(0, 0), value=0)
                  (conv): Conv1d(5, 32, kernel_size=(1,), stride=(1,), bias=False)
                )
                (activation): Hardswish()
                (mult): FloatFunctional(
                  (activation_post_process): Identity()
                )
              )
              (8): CausalConv1d(
                (pad): ConstantPad1d(padding=(0, 0), value=0)
                (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)
              )
              (9): BatchNorm1d(32, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)
            )
            (op): FloatFunctional(
              (activation_post_process): Identity()
            )
          )
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Dropout(p=0.3, inplace=False)
        )
        (1): Sequential(
          (0): PhiNetCausalConvBlock(
            (_layers): ModuleList(
              (0): CausalConv1d(
                (pad): ConstantPad1d(padding=(0, 0), value=0)
                (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)
              )
              (1): BatchNorm1d(32, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)
              (2): Hardswish()
              (3): Dropout1d(p=0.05, inplace=False)
              (4): DepthwiseCausalConv(
                (pad): ConstantPad1d(padding=(4, 0), value=0)
                (conv): Conv1d(32, 32, kernel_size=(3,), stride=(1,), dilation=(2,), groups=32, bias=False)
              )
              (5): BatchNorm1d(32, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)
              (6): Hardswish()
              (7): SEBlock(
                (se_conv): CausalConv1d(
                  (pad): ConstantPad1d(padding=(0, 0), value=0)
                  (conv): Conv1d(32, 5, kernel_size=(1,), stride=(1,), bias=False)
                )
                (se_conv2): CausalConv1d(
                  (pad): ConstantPad1d(padding=(0, 0), value=0)
                  (conv): Conv1d(5, 32, kernel_size=(1,), stride=(1,), bias=False)
                )
                (activation): Hardswish()
                (mult): FloatFunctional(
                  (activation_post_process): Identity()
                )
              )
              (8): CausalConv1d(
                (pad): ConstantPad1d(padding=(0, 0), value=0)
                (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)
              )
              (9): BatchNorm1d(32, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)
            )
            (op): FloatFunctional(
              (activation_post_process): Identity()
            )
          )
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Dropout(p=0.3, inplace=False)
        )
      )
      (2): ModuleList(
        (0-1): 2 x Sequential(
          (0): PhiNetCausalConvBlock(
            (_layers): ModuleList(
              (0): CausalConv1d(
                (pad): ConstantPad1d(padding=(0, 0), value=0)
                (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)
              )
              (1): BatchNorm1d(32, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)
              (2): Hardswish()
              (3): Dropout1d(p=0.05, inplace=False)
              (4): DepthwiseCausalConv(
                (pad): ConstantPad1d(padding=(2, 0), value=0)
                (conv): Conv1d(32, 32, kernel_size=(3,), stride=(1,), groups=32, bias=False)
              )
              (5): BatchNorm1d(32, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)
              (6): Hardswish()
              (7): SEBlock(
                (se_conv): CausalConv1d(
                  (pad): ConstantPad1d(padding=(0, 0), value=0)
                  (conv): Conv1d(32, 5, kernel_size=(1,), stride=(1,), bias=False)
                )
                (se_conv2): CausalConv1d(
                  (pad): ConstantPad1d(padding=(0, 0), value=0)
                  (conv): Conv1d(5, 32, kernel_size=(1,), stride=(1,), bias=False)
                )
                (activation): Hardswish()
                (mult): FloatFunctional(
                  (activation_post_process): Identity()
                )
              )
              (8): CausalConv1d(
                (pad): ConstantPad1d(padding=(0, 0), value=0)
                (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)
              )
              (9): BatchNorm1d(32, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)
            )
            (op): FloatFunctional(
              (activation_post_process): Identity()
            )
          )
          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
          (3): Dropout(p=0.3, inplace=False)
        )
      )
    )
    (projections_modulelist): ModuleList(
      (0-2): 3 x Identity()
    )
    (final_block_to_conv1_projection): Identity()
    (final_conv1_module): Sequential(
      (0): PhiNetCausalConvBlock(
        (_layers): ModuleList(
          (0): CausalConv1d(
            (pad): ConstantPad1d(padding=(0, 0), value=0)
            (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)
          )
          (1): BatchNorm1d(32, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)
          (2): Hardswish()
          (3): Dropout1d(p=0.05, inplace=False)
          (4): DepthwiseCausalConv(
            (pad): ConstantPad1d(padding=(8, 0), value=0)
            (conv): Conv1d(32, 32, kernel_size=(5,), stride=(1,), dilation=(2,), groups=32, bias=False)
          )
          (5): BatchNorm1d(32, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)
          (6): Hardswish()
          (7): SEBlock(
            (se_conv): CausalConv1d(
              (pad): ConstantPad1d(padding=(0, 0), value=0)
              (conv): Conv1d(32, 5, kernel_size=(1,), stride=(1,), bias=False)
            )
            (se_conv2): CausalConv1d(
              (pad): ConstantPad1d(padding=(0, 0), value=0)
              (conv): Conv1d(5, 32, kernel_size=(1,), stride=(1,), bias=False)
            )
            (activation): Hardswish()
            (mult): FloatFunctional(
              (activation_post_process): Identity()
            )
          )
          (8): CausalConv1d(
            (pad): ConstantPad1d(padding=(0, 0), value=0)
            (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)
          )
          (9): BatchNorm1d(32, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)
        )
      )
      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.3, inplace=False)
    )
    (conv1_to_conv2_projection): Identity()
    (final_conv2_module): Sequential(
      (0): PhiNetCausalConvBlock(
        (_layers): ModuleList(
          (0): CausalConv1d(
            (pad): ConstantPad1d(padding=(0, 0), value=0)
            (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)
          )
          (1): BatchNorm1d(32, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)
          (2): Hardswish()
          (3): Dropout1d(p=0.05, inplace=False)
          (4): DepthwiseCausalConv(
            (pad): ConstantPad1d(padding=(0, 0), value=0)
            (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), groups=32, bias=False)
          )
          (5): BatchNorm1d(32, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)
          (6): Hardswish()
          (7): SEBlock(
            (se_conv): CausalConv1d(
              (pad): ConstantPad1d(padding=(0, 0), value=0)
              (conv): Conv1d(32, 5, kernel_size=(1,), stride=(1,), bias=False)
            )
            (se_conv2): CausalConv1d(
              (pad): ConstantPad1d(padding=(0, 0), value=0)
              (conv): Conv1d(5, 32, kernel_size=(1,), stride=(1,), bias=False)
            )
            (activation): Hardswish()
            (mult): FloatFunctional(
              (activation_post_process): Identity()
            )
          )
          (8): CausalConv1d(
            (pad): ConstantPad1d(padding=(0, 0), value=0)
            (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)
          )
          (9): BatchNorm1d(32, eps=0.001, momentum=0.999, affine=True, track_running_stats=True)
        )
      )
      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.3, inplace=False)
    )
  )
  (gru): GRU(32, 64, batch_first=True)
  (projection): Linear(in_features=64, out_features=64, bias=True)
  (keyword_attention): AttentionLayer(
    (attention): Linear(in_features=64, out_features=1, bias=True)
  )
  (fc): Linear(in_features=64, out_features=9, bias=True)
)
[2025-05-27 14:43:27,667][__main__][INFO] - Total parameters: 53,516
[2025-05-27 14:43:27,667][__main__][INFO] - Trainable parameters: 53,516
[2025-05-27 14:43:27,667][__main__][INFO] - Computing model complexity...
[2025-05-27 14:43:27,667][__main__][INFO] - Model MACs: None
[2025-05-27 14:43:27,667][__main__][INFO] - Starting training...
[2025-05-27 14:53:25,206][__main__][INFO] - Epoch 1 - Breakpoint: 3768.69 Hz, Transition Width: 95.59
[2025-05-27 14:53:25,206][__main__][INFO] - Epoch 1/50
[2025-05-27 14:53:25,206][__main__][INFO] - Train Loss: 1.4928, Train Acc: 47.59%
[2025-05-27 14:53:25,207][__main__][INFO] - Val Loss: 1.0763, Val Acc: 64.98%
[2025-05-27 14:53:25,207][__main__][INFO] - Val Precision (w): 0.6514, Val Recall (w): 0.6498, Val F1 (w): 0.6315
[2025-05-27 14:53:25,207][__main__][INFO] - Learning Rate: 0.001000
[2025-05-27 14:53:25,244][__main__][INFO] - Validation loss improved from 1.0773 to 1.0763
[2025-05-27 14:53:25,244][__main__][INFO] - New best model saved with val acc: 64.98%
[2025-05-27 15:03:24,301][__main__][INFO] - Epoch 2 - Breakpoint: 3620.61 Hz, Transition Width: 88.88
[2025-05-27 15:03:24,302][__main__][INFO] - Epoch 2/50
[2025-05-27 15:03:24,302][__main__][INFO] - Train Loss: 1.0906, Train Acc: 64.13%
[2025-05-27 15:03:24,302][__main__][INFO] - Val Loss: 0.8781, Val Acc: 72.12%
[2025-05-27 15:03:24,302][__main__][INFO] - Val Precision (w): 0.7175, Val Recall (w): 0.7212, Val F1 (w): 0.7101
[2025-05-27 15:03:24,302][__main__][INFO] - Learning Rate: 0.001000
[2025-05-27 15:03:24,324][__main__][INFO] - Validation loss improved from 0.8791 to 0.8781
[2025-05-27 15:03:24,324][__main__][INFO] - New best model saved with val acc: 72.12%
[2025-05-27 15:13:21,912][__main__][INFO] - Epoch 3 - Breakpoint: 3571.32 Hz, Transition Width: 83.58
[2025-05-27 15:13:21,913][__main__][INFO] - Epoch 3/50
[2025-05-27 15:13:21,913][__main__][INFO] - Train Loss: 0.9558, Train Acc: 68.63%
[2025-05-27 15:13:21,913][__main__][INFO] - Val Loss: 0.8091, Val Acc: 74.38%
[2025-05-27 15:13:21,913][__main__][INFO] - Val Precision (w): 0.7499, Val Recall (w): 0.7438, Val F1 (w): 0.7378
[2025-05-27 15:13:21,913][__main__][INFO] - Learning Rate: 0.001000
[2025-05-27 15:13:21,939][__main__][INFO] - Validation loss improved from 0.8101 to 0.8091
[2025-05-27 15:13:21,939][__main__][INFO] - New best model saved with val acc: 74.38%
[2025-05-27 15:23:24,626][__main__][INFO] - Epoch 4 - Breakpoint: 3467.38 Hz, Transition Width: 79.49
[2025-05-27 15:23:24,626][__main__][INFO] - Epoch 4/50
[2025-05-27 15:23:24,626][__main__][INFO] - Train Loss: 0.8605, Train Acc: 72.29%
[2025-05-27 15:23:24,626][__main__][INFO] - Val Loss: 0.8063, Val Acc: 74.20%
[2025-05-27 15:23:24,627][__main__][INFO] - Val Precision (w): 0.7547, Val Recall (w): 0.7420, Val F1 (w): 0.7388
[2025-05-27 15:23:24,627][__main__][INFO] - Learning Rate: 0.001000
[2025-05-27 15:23:24,660][__main__][INFO] - Validation loss improved from 0.8073 to 0.8063
[2025-05-27 15:23:24,660][__main__][INFO] - New best model saved with val acc: 74.20%
[2025-05-27 15:33:37,829][__main__][INFO] - Epoch 5 - Breakpoint: 3354.49 Hz, Transition Width: 78.30
[2025-05-27 15:33:37,829][__main__][INFO] - Epoch 5/50
[2025-05-27 15:33:37,829][__main__][INFO] - Train Loss: 0.8146, Train Acc: 73.08%
[2025-05-27 15:33:37,829][__main__][INFO] - Val Loss: 0.7099, Val Acc: 78.18%
[2025-05-27 15:33:37,829][__main__][INFO] - Val Precision (w): 0.7833, Val Recall (w): 0.7818, Val F1 (w): 0.7767
[2025-05-27 15:33:37,829][__main__][INFO] - Learning Rate: 0.001000
[2025-05-27 15:33:37,855][__main__][INFO] - Validation loss improved from 0.7109 to 0.7099
[2025-05-27 15:33:37,856][__main__][INFO] - New best model saved with val acc: 78.18%
[2025-05-27 15:43:43,266][__main__][INFO] - Epoch 6 - Breakpoint: 3282.86 Hz, Transition Width: 75.77
[2025-05-27 15:43:43,267][__main__][INFO] - Epoch 6/50
[2025-05-27 15:43:43,267][__main__][INFO] - Train Loss: 0.7745, Train Acc: 74.58%
[2025-05-27 15:43:43,267][__main__][INFO] - Val Loss: 0.6908, Val Acc: 77.71%
[2025-05-27 15:43:43,267][__main__][INFO] - Val Precision (w): 0.7823, Val Recall (w): 0.7771, Val F1 (w): 0.7753
[2025-05-27 15:43:43,267][__main__][INFO] - Learning Rate: 0.001000
[2025-05-27 15:43:43,314][__main__][INFO] - Validation loss improved from 0.6918 to 0.6908
[2025-05-27 15:43:43,314][__main__][INFO] - New best model saved with val acc: 77.71%
[2025-05-27 15:53:48,727][__main__][INFO] - Epoch 7 - Breakpoint: 3203.40 Hz, Transition Width: 70.36
[2025-05-27 15:53:48,727][__main__][INFO] - Epoch 7/50
[2025-05-27 15:53:48,728][__main__][INFO] - Train Loss: 0.7398, Train Acc: 75.97%
[2025-05-27 15:53:48,728][__main__][INFO] - Val Loss: 0.6536, Val Acc: 79.55%
[2025-05-27 15:53:48,728][__main__][INFO] - Val Precision (w): 0.8001, Val Recall (w): 0.7955, Val F1 (w): 0.7962
[2025-05-27 15:53:48,728][__main__][INFO] - Learning Rate: 0.001000
[2025-05-27 15:53:48,759][__main__][INFO] - Validation loss improved from 0.6546 to 0.6536
[2025-05-27 15:53:48,759][__main__][INFO] - New best model saved with val acc: 79.55%
[2025-05-27 16:03:53,916][__main__][INFO] - Epoch 8 - Breakpoint: 3114.55 Hz, Transition Width: 67.00
[2025-05-27 16:03:53,916][__main__][INFO] - Epoch 8/50
[2025-05-27 16:03:53,916][__main__][INFO] - Train Loss: 0.6923, Train Acc: 77.92%
[2025-05-27 16:03:53,916][__main__][INFO] - Val Loss: 0.6706, Val Acc: 79.90%
[2025-05-27 16:03:53,916][__main__][INFO] - Val Precision (w): 0.8104, Val Recall (w): 0.7990, Val F1 (w): 0.7934
[2025-05-27 16:03:53,916][__main__][INFO] - Learning Rate: 0.001000
[2025-05-27 16:03:53,953][__main__][INFO] - New best model saved with val acc: 79.90% (val_loss: 0.6706)
[2025-05-27 16:03:53,953][__main__][INFO] - No improvement in validation loss for 1/10 epochs
[2025-05-27 16:14:25,519][__main__][INFO] - Epoch 9 - Breakpoint: 2992.59 Hz, Transition Width: 62.30
[2025-05-27 16:14:25,520][__main__][INFO] - Epoch 9/50
[2025-05-27 16:14:25,520][__main__][INFO] - Train Loss: 0.6883, Train Acc: 77.71%
[2025-05-27 16:14:25,520][__main__][INFO] - Val Loss: 0.6326, Val Acc: 80.20%
[2025-05-27 16:14:25,520][__main__][INFO] - Val Precision (w): 0.8132, Val Recall (w): 0.8020, Val F1 (w): 0.8007
[2025-05-27 16:14:25,520][__main__][INFO] - Learning Rate: 0.001000
[2025-05-27 16:14:25,551][__main__][INFO] - Validation loss improved from 0.6336 to 0.6326
[2025-05-27 16:14:25,551][__main__][INFO] - New best model saved with val acc: 80.20%
[2025-05-27 16:24:20,021][__main__][INFO] - Epoch 10 - Breakpoint: 2942.36 Hz, Transition Width: 58.53
[2025-05-27 16:24:20,021][__main__][INFO] - Epoch 10/50
[2025-05-27 16:24:20,021][__main__][INFO] - Train Loss: 0.6702, Train Acc: 78.38%
[2025-05-27 16:24:20,021][__main__][INFO] - Val Loss: 0.7403, Val Acc: 75.92%
[2025-05-27 16:24:20,021][__main__][INFO] - Val Precision (w): 0.7655, Val Recall (w): 0.7592, Val F1 (w): 0.7540
[2025-05-27 16:24:20,022][__main__][INFO] - Learning Rate: 0.001000
[2025-05-27 16:24:20,022][__main__][INFO] - No improvement in validation loss for 1/10 epochs
[2025-05-27 16:34:23,307][__main__][INFO] - Epoch 11 - Breakpoint: 2887.75 Hz, Transition Width: 58.57
[2025-05-27 16:34:23,307][__main__][INFO] - Epoch 11/50
[2025-05-27 16:34:23,307][__main__][INFO] - Train Loss: 0.6441, Train Acc: 79.55%
[2025-05-27 16:34:23,307][__main__][INFO] - Val Loss: 0.5981, Val Acc: 81.45%
[2025-05-27 16:34:23,308][__main__][INFO] - Val Precision (w): 0.8191, Val Recall (w): 0.8145, Val F1 (w): 0.8127
[2025-05-27 16:34:23,308][__main__][INFO] - Learning Rate: 0.001000
[2025-05-27 16:34:23,340][__main__][INFO] - Validation loss improved from 0.5991 to 0.5981
[2025-05-27 16:34:23,340][__main__][INFO] - New best model saved with val acc: 81.45%
[2025-05-27 16:44:30,317][__main__][INFO] - Epoch 12 - Breakpoint: 2806.52 Hz, Transition Width: 57.34
[2025-05-27 16:44:30,318][__main__][INFO] - Epoch 12/50
[2025-05-27 16:44:30,318][__main__][INFO] - Train Loss: 0.6211, Train Acc: 79.56%
[2025-05-27 16:44:30,318][__main__][INFO] - Val Loss: 0.6015, Val Acc: 80.98%
[2025-05-27 16:44:30,318][__main__][INFO] - Val Precision (w): 0.8128, Val Recall (w): 0.8098, Val F1 (w): 0.8073
[2025-05-27 16:44:30,318][__main__][INFO] - Learning Rate: 0.001000
[2025-05-27 16:44:30,318][__main__][INFO] - No improvement in validation loss for 1/10 epochs
[2025-05-27 16:54:57,282][__main__][INFO] - Epoch 13 - Breakpoint: 2762.32 Hz, Transition Width: 56.10
[2025-05-27 16:54:57,283][__main__][INFO] - Epoch 13/50
[2025-05-27 16:54:57,283][__main__][INFO] - Train Loss: 0.6109, Train Acc: 79.88%
[2025-05-27 16:54:57,283][__main__][INFO] - Val Loss: 0.6220, Val Acc: 80.38%
[2025-05-27 16:54:57,283][__main__][INFO] - Val Precision (w): 0.8226, Val Recall (w): 0.8038, Val F1 (w): 0.8071
[2025-05-27 16:54:57,283][__main__][INFO] - Learning Rate: 0.001000
[2025-05-27 16:54:57,284][__main__][INFO] - No improvement in validation loss for 2/10 epochs
[2025-05-27 17:05:10,826][__main__][INFO] - Epoch 14 - Breakpoint: 2693.28 Hz, Transition Width: 54.59
[2025-05-27 17:05:10,826][__main__][INFO] - Epoch 14/50
[2025-05-27 17:05:10,826][__main__][INFO] - Train Loss: 0.5996, Train Acc: 80.27%
[2025-05-27 17:05:10,826][__main__][INFO] - Val Loss: 0.5981, Val Acc: 80.98%
[2025-05-27 17:05:10,827][__main__][INFO] - Val Precision (w): 0.8142, Val Recall (w): 0.8098, Val F1 (w): 0.8076
[2025-05-27 17:05:10,827][__main__][INFO] - Learning Rate: 0.001000
[2025-05-27 17:05:10,827][__main__][INFO] - No improvement in validation loss for 3/10 epochs
[2025-05-27 17:15:07,489][__main__][INFO] - Epoch 15 - Breakpoint: 2655.51 Hz, Transition Width: 53.67
[2025-05-27 17:15:07,489][__main__][INFO] - Epoch 15/50
[2025-05-27 17:15:07,489][__main__][INFO] - Train Loss: 0.5831, Train Acc: 81.08%
[2025-05-27 17:15:07,489][__main__][INFO] - Val Loss: 0.5809, Val Acc: 82.58%
[2025-05-27 17:15:07,490][__main__][INFO] - Val Precision (w): 0.8300, Val Recall (w): 0.8258, Val F1 (w): 0.8255
[2025-05-27 17:15:07,490][__main__][INFO] - Learning Rate: 0.001000
[2025-05-27 17:15:07,520][__main__][INFO] - Validation loss improved from 0.5819 to 0.5809
[2025-05-27 17:15:07,520][__main__][INFO] - New best model saved with val acc: 82.58%
[2025-05-27 17:25:30,877][__main__][INFO] - Epoch 16 - Breakpoint: 2636.19 Hz, Transition Width: 54.03
[2025-05-27 17:25:30,878][__main__][INFO] - Epoch 16/50
[2025-05-27 17:25:30,878][__main__][INFO] - Train Loss: 0.5855, Train Acc: 80.80%
[2025-05-27 17:25:30,878][__main__][INFO] - Val Loss: 0.5937, Val Acc: 82.40%
[2025-05-27 17:25:30,878][__main__][INFO] - Val Precision (w): 0.8335, Val Recall (w): 0.8240, Val F1 (w): 0.8214
[2025-05-27 17:25:30,878][__main__][INFO] - Learning Rate: 0.001000
[2025-05-27 17:25:30,878][__main__][INFO] - No improvement in validation loss for 1/10 epochs
[2025-05-27 17:35:24,204][__main__][INFO] - Epoch 17 - Breakpoint: 2552.90 Hz, Transition Width: 53.06
[2025-05-27 17:35:24,204][__main__][INFO] - Epoch 17/50
[2025-05-27 17:35:24,204][__main__][INFO] - Train Loss: 0.5631, Train Acc: 81.55%
[2025-05-27 17:35:24,205][__main__][INFO] - Val Loss: 0.5559, Val Acc: 82.94%
[2025-05-27 17:35:24,205][__main__][INFO] - Val Precision (w): 0.8300, Val Recall (w): 0.8294, Val F1 (w): 0.8274
[2025-05-27 17:35:24,205][__main__][INFO] - Learning Rate: 0.001000
[2025-05-27 17:35:24,255][__main__][INFO] - Validation loss improved from 0.5569 to 0.5559
[2025-05-27 17:35:24,256][__main__][INFO] - New best model saved with val acc: 82.94%
[2025-05-27 17:45:24,963][__main__][INFO] - Epoch 18 - Breakpoint: 2477.27 Hz, Transition Width: 53.27
[2025-05-27 17:45:24,963][__main__][INFO] - Epoch 18/50
[2025-05-27 17:45:24,963][__main__][INFO] - Train Loss: 0.5555, Train Acc: 82.04%
[2025-05-27 17:45:24,963][__main__][INFO] - Val Loss: 0.5362, Val Acc: 83.71%
[2025-05-27 17:45:24,963][__main__][INFO] - Val Precision (w): 0.8388, Val Recall (w): 0.8371, Val F1 (w): 0.8372
[2025-05-27 17:45:24,963][__main__][INFO] - Learning Rate: 0.001000
[2025-05-27 17:45:24,993][__main__][INFO] - Validation loss improved from 0.5372 to 0.5362
[2025-05-27 17:45:24,994][__main__][INFO] - New best model saved with val acc: 83.71%
[2025-05-27 17:55:34,446][__main__][INFO] - Epoch 19 - Breakpoint: 2427.20 Hz, Transition Width: 54.81
[2025-05-27 17:55:34,447][__main__][INFO] - Epoch 19/50
[2025-05-27 17:55:34,447][__main__][INFO] - Train Loss: 0.5463, Train Acc: 82.21%
[2025-05-27 17:55:34,447][__main__][INFO] - Val Loss: 0.5479, Val Acc: 82.82%
[2025-05-27 17:55:34,447][__main__][INFO] - Val Precision (w): 0.8314, Val Recall (w): 0.8282, Val F1 (w): 0.8259
[2025-05-27 17:55:34,447][__main__][INFO] - Learning Rate: 0.001000
[2025-05-27 17:55:34,447][__main__][INFO] - No improvement in validation loss for 1/10 epochs
[2025-05-27 18:05:48,669][__main__][INFO] - Epoch 20 - Breakpoint: 2393.72 Hz, Transition Width: 53.93
[2025-05-27 18:05:48,669][__main__][INFO] - Epoch 20/50
[2025-05-27 18:05:48,669][__main__][INFO] - Train Loss: 0.5371, Train Acc: 82.55%
[2025-05-27 18:05:48,669][__main__][INFO] - Val Loss: 0.5228, Val Acc: 84.01%
[2025-05-27 18:05:48,669][__main__][INFO] - Val Precision (w): 0.8403, Val Recall (w): 0.8401, Val F1 (w): 0.8395
[2025-05-27 18:05:48,669][__main__][INFO] - Learning Rate: 0.001000
[2025-05-27 18:05:48,697][__main__][INFO] - Validation loss improved from 0.5238 to 0.5228
[2025-05-27 18:05:48,698][__main__][INFO] - New best model saved with val acc: 84.01%
[2025-05-27 18:15:56,786][__main__][INFO] - Epoch 21 - Breakpoint: 2377.14 Hz, Transition Width: 53.10
[2025-05-27 18:15:56,787][__main__][INFO] - Epoch 21/50
[2025-05-27 18:15:56,787][__main__][INFO] - Train Loss: 0.5260, Train Acc: 82.23%
[2025-05-27 18:15:56,787][__main__][INFO] - Val Loss: 0.5170, Val Acc: 83.89%
[2025-05-27 18:15:56,787][__main__][INFO] - Val Precision (w): 0.8436, Val Recall (w): 0.8389, Val F1 (w): 0.8398
[2025-05-27 18:15:56,787][__main__][INFO] - Learning Rate: 0.001000
[2025-05-27 18:15:56,817][__main__][INFO] - Validation loss improved from 0.5180 to 0.5170
[2025-05-27 18:15:56,817][__main__][INFO] - New best model saved with val acc: 83.89%
[2025-05-27 18:26:13,980][__main__][INFO] - Epoch 22 - Breakpoint: 2324.42 Hz, Transition Width: 54.23
[2025-05-27 18:26:13,980][__main__][INFO] - Epoch 22/50
[2025-05-27 18:26:13,980][__main__][INFO] - Train Loss: 0.5147, Train Acc: 83.35%
[2025-05-27 18:26:13,980][__main__][INFO] - Val Loss: 0.5171, Val Acc: 83.95%
[2025-05-27 18:26:13,980][__main__][INFO] - Val Precision (w): 0.8390, Val Recall (w): 0.8395, Val F1 (w): 0.8386
[2025-05-27 18:26:13,980][__main__][INFO] - Learning Rate: 0.001000
[2025-05-27 18:26:14,011][__main__][INFO] - New best model saved with val acc: 83.95% (val_loss: 0.5171)
[2025-05-27 18:26:14,012][__main__][INFO] - No improvement in validation loss for 1/10 epochs
[2025-05-27 18:36:20,133][__main__][INFO] - Epoch 23 - Breakpoint: 2216.71 Hz, Transition Width: 51.73
[2025-05-27 18:36:20,134][__main__][INFO] - Epoch 23/50
[2025-05-27 18:36:20,134][__main__][INFO] - Train Loss: 0.5214, Train Acc: 82.61%
[2025-05-27 18:36:20,134][__main__][INFO] - Val Loss: 0.5575, Val Acc: 83.41%
[2025-05-27 18:36:20,134][__main__][INFO] - Val Precision (w): 0.8376, Val Recall (w): 0.8341, Val F1 (w): 0.8310
[2025-05-27 18:36:20,134][__main__][INFO] - Learning Rate: 0.001000
[2025-05-27 18:36:20,135][__main__][INFO] - No improvement in validation loss for 2/10 epochs
[2025-05-27 18:46:20,059][__main__][INFO] - Epoch 24 - Breakpoint: 2185.51 Hz, Transition Width: 53.93
[2025-05-27 18:46:20,059][__main__][INFO] - Epoch 24/50
[2025-05-27 18:46:20,059][__main__][INFO] - Train Loss: 0.5108, Train Acc: 83.61%
[2025-05-27 18:46:20,060][__main__][INFO] - Val Loss: 0.5363, Val Acc: 84.07%
[2025-05-27 18:46:20,060][__main__][INFO] - Val Precision (w): 0.8506, Val Recall (w): 0.8407, Val F1 (w): 0.8388
[2025-05-27 18:46:20,060][__main__][INFO] - Learning Rate: 0.001000
[2025-05-27 18:46:20,091][__main__][INFO] - New best model saved with val acc: 84.07% (val_loss: 0.5363)
[2025-05-27 18:46:20,092][__main__][INFO] - No improvement in validation loss for 3/10 epochs
[2025-05-27 18:56:25,803][__main__][INFO] - Epoch 25 - Breakpoint: 2118.34 Hz, Transition Width: 55.04
[2025-05-27 18:56:25,804][__main__][INFO] - Epoch 25/50
[2025-05-27 18:56:25,804][__main__][INFO] - Train Loss: 0.5005, Train Acc: 83.76%
[2025-05-27 18:56:25,804][__main__][INFO] - Val Loss: 0.5374, Val Acc: 84.30%
[2025-05-27 18:56:25,804][__main__][INFO] - Val Precision (w): 0.8452, Val Recall (w): 0.8430, Val F1 (w): 0.8414
[2025-05-27 18:56:25,805][__main__][INFO] - Learning Rate: 0.001000
[2025-05-27 18:56:25,849][__main__][INFO] - New best model saved with val acc: 84.30% (val_loss: 0.5374)
[2025-05-27 18:56:25,849][__main__][INFO] - No improvement in validation loss for 4/10 epochs
[2025-05-27 19:06:32,564][__main__][INFO] - Epoch 26 - Breakpoint: 2099.62 Hz, Transition Width: 56.02
[2025-05-27 19:06:32,564][__main__][INFO] - Epoch 26/50
[2025-05-27 19:06:32,565][__main__][INFO] - Train Loss: 0.4774, Train Acc: 84.42%
[2025-05-27 19:06:32,565][__main__][INFO] - Val Loss: 0.4856, Val Acc: 85.61%
[2025-05-27 19:06:32,565][__main__][INFO] - Val Precision (w): 0.8587, Val Recall (w): 0.8561, Val F1 (w): 0.8568
[2025-05-27 19:06:32,565][__main__][INFO] - Learning Rate: 0.000500
[2025-05-27 19:06:32,599][__main__][INFO] - Validation loss improved from 0.4866 to 0.4856
[2025-05-27 19:06:32,599][__main__][INFO] - New best model saved with val acc: 85.61%
[2025-05-27 19:16:40,249][__main__][INFO] - Epoch 27 - Breakpoint: 2111.57 Hz, Transition Width: 56.76
[2025-05-27 19:16:40,250][__main__][INFO] - Epoch 27/50
[2025-05-27 19:16:40,250][__main__][INFO] - Train Loss: 0.4608, Train Acc: 84.83%
[2025-05-27 19:16:40,250][__main__][INFO] - Val Loss: 0.4808, Val Acc: 85.32%
[2025-05-27 19:16:40,250][__main__][INFO] - Val Precision (w): 0.8534, Val Recall (w): 0.8532, Val F1 (w): 0.8524
[2025-05-27 19:16:40,250][__main__][INFO] - Learning Rate: 0.000500
[2025-05-27 19:16:40,281][__main__][INFO] - Validation loss improved from 0.4818 to 0.4808
[2025-05-27 19:16:40,281][__main__][INFO] - New best model saved with val acc: 85.32%
[2025-05-27 19:26:41,415][__main__][INFO] - Epoch 28 - Breakpoint: 2068.40 Hz, Transition Width: 56.92
[2025-05-27 19:26:41,416][__main__][INFO] - Epoch 28/50
[2025-05-27 19:26:41,416][__main__][INFO] - Train Loss: 0.4501, Train Acc: 85.20%
[2025-05-27 19:26:41,416][__main__][INFO] - Val Loss: 0.4849, Val Acc: 85.91%
[2025-05-27 19:26:41,416][__main__][INFO] - Val Precision (w): 0.8590, Val Recall (w): 0.8591, Val F1 (w): 0.8584
[2025-05-27 19:26:41,416][__main__][INFO] - Learning Rate: 0.000500
[2025-05-27 19:26:41,455][__main__][INFO] - New best model saved with val acc: 85.91% (val_loss: 0.4849)
[2025-05-27 19:26:41,455][__main__][INFO] - No improvement in validation loss for 1/10 epochs
[2025-05-27 19:36:49,727][__main__][INFO] - Epoch 29 - Breakpoint: 2055.98 Hz, Transition Width: 57.68
[2025-05-27 19:36:49,727][__main__][INFO] - Epoch 29/50
[2025-05-27 19:36:49,727][__main__][INFO] - Train Loss: 0.4584, Train Acc: 84.90%
[2025-05-27 19:36:49,727][__main__][INFO] - Val Loss: 0.5004, Val Acc: 85.14%
[2025-05-27 19:36:49,727][__main__][INFO] - Val Precision (w): 0.8521, Val Recall (w): 0.8514, Val F1 (w): 0.8497
[2025-05-27 19:36:49,727][__main__][INFO] - Learning Rate: 0.000500
[2025-05-27 19:36:49,728][__main__][INFO] - No improvement in validation loss for 2/10 epochs
[2025-05-27 19:46:55,191][__main__][INFO] - Epoch 30 - Breakpoint: 2040.70 Hz, Transition Width: 57.00
[2025-05-27 19:46:55,191][__main__][INFO] - Epoch 30/50
[2025-05-27 19:46:55,192][__main__][INFO] - Train Loss: 0.4458, Train Acc: 85.30%
[2025-05-27 19:46:55,192][__main__][INFO] - Val Loss: 0.4931, Val Acc: 84.54%
[2025-05-27 19:46:55,192][__main__][INFO] - Val Precision (w): 0.8496, Val Recall (w): 0.8454, Val F1 (w): 0.8448
[2025-05-27 19:46:55,192][__main__][INFO] - Learning Rate: 0.000500
[2025-05-27 19:46:55,192][__main__][INFO] - No improvement in validation loss for 3/10 epochs
[2025-05-27 19:57:06,032][__main__][INFO] - Epoch 31 - Breakpoint: 2054.07 Hz, Transition Width: 56.47
[2025-05-27 19:57:06,032][__main__][INFO] - Epoch 31/50
[2025-05-27 19:57:06,032][__main__][INFO] - Train Loss: 0.4549, Train Acc: 84.98%
[2025-05-27 19:57:06,032][__main__][INFO] - Val Loss: 0.4791, Val Acc: 85.14%
[2025-05-27 19:57:06,032][__main__][INFO] - Val Precision (w): 0.8541, Val Recall (w): 0.8514, Val F1 (w): 0.8498
[2025-05-27 19:57:06,032][__main__][INFO] - Learning Rate: 0.000500
[2025-05-27 19:57:06,069][__main__][INFO] - Validation loss improved from 0.4801 to 0.4791
[2025-05-27 19:57:06,069][__main__][INFO] - New best model saved with val acc: 85.14%
[2025-05-27 20:07:16,839][__main__][INFO] - Epoch 32 - Breakpoint: 2053.74 Hz, Transition Width: 57.06
[2025-05-27 20:07:16,839][__main__][INFO] - Epoch 32/50
[2025-05-27 20:07:16,839][__main__][INFO] - Train Loss: 0.4479, Train Acc: 85.28%
[2025-05-27 20:07:16,839][__main__][INFO] - Val Loss: 0.5339, Val Acc: 83.17%
[2025-05-27 20:07:16,839][__main__][INFO] - Val Precision (w): 0.8364, Val Recall (w): 0.8317, Val F1 (w): 0.8311
[2025-05-27 20:07:16,839][__main__][INFO] - Learning Rate: 0.000500
[2025-05-27 20:07:16,839][__main__][INFO] - No improvement in validation loss for 1/10 epochs
[2025-05-27 20:17:11,938][__main__][INFO] - Epoch 33 - Breakpoint: 2047.45 Hz, Transition Width: 58.49
[2025-05-27 20:17:11,939][__main__][INFO] - Epoch 33/50
[2025-05-27 20:17:11,939][__main__][INFO] - Train Loss: 0.4312, Train Acc: 85.96%
[2025-05-27 20:17:11,939][__main__][INFO] - Val Loss: 0.4921, Val Acc: 84.96%
[2025-05-27 20:17:11,939][__main__][INFO] - Val Precision (w): 0.8503, Val Recall (w): 0.8496, Val F1 (w): 0.8485
[2025-05-27 20:17:11,939][__main__][INFO] - Learning Rate: 0.000500
[2025-05-27 20:17:11,939][__main__][INFO] - No improvement in validation loss for 2/10 epochs
[2025-05-27 20:27:22,134][__main__][INFO] - Epoch 34 - Breakpoint: 2021.90 Hz, Transition Width: 59.86
[2025-05-27 20:27:22,135][__main__][INFO] - Epoch 34/50
[2025-05-27 20:27:22,135][__main__][INFO] - Train Loss: 0.4380, Train Acc: 85.67%
[2025-05-27 20:27:22,135][__main__][INFO] - Val Loss: 0.4851, Val Acc: 85.14%
[2025-05-27 20:27:22,135][__main__][INFO] - Val Precision (w): 0.8540, Val Recall (w): 0.8514, Val F1 (w): 0.8519
[2025-05-27 20:27:22,135][__main__][INFO] - Learning Rate: 0.000500
[2025-05-27 20:27:22,135][__main__][INFO] - No improvement in validation loss for 3/10 epochs
[2025-05-27 20:37:24,241][__main__][INFO] - Epoch 35 - Breakpoint: 2010.25 Hz, Transition Width: 60.40
[2025-05-27 20:37:24,242][__main__][INFO] - Epoch 35/50
[2025-05-27 20:37:24,242][__main__][INFO] - Train Loss: 0.4242, Train Acc: 86.33%
[2025-05-27 20:37:24,242][__main__][INFO] - Val Loss: 0.5009, Val Acc: 84.84%
[2025-05-27 20:37:24,242][__main__][INFO] - Val Precision (w): 0.8527, Val Recall (w): 0.8484, Val F1 (w): 0.8464
[2025-05-27 20:37:24,242][__main__][INFO] - Learning Rate: 0.000500
[2025-05-27 20:37:24,242][__main__][INFO] - No improvement in validation loss for 4/10 epochs
[2025-05-27 20:47:43,556][__main__][INFO] - Epoch 36 - Breakpoint: 2000.87 Hz, Transition Width: 60.49
[2025-05-27 20:47:43,557][__main__][INFO] - Epoch 36/50
[2025-05-27 20:47:43,557][__main__][INFO] - Train Loss: 0.4084, Train Acc: 86.82%
[2025-05-27 20:47:43,557][__main__][INFO] - Val Loss: 0.4749, Val Acc: 84.84%
[2025-05-27 20:47:43,557][__main__][INFO] - Val Precision (w): 0.8494, Val Recall (w): 0.8484, Val F1 (w): 0.8474
[2025-05-27 20:47:43,557][__main__][INFO] - Learning Rate: 0.000250
[2025-05-27 20:47:43,587][__main__][INFO] - Validation loss improved from 0.4759 to 0.4749
[2025-05-27 20:47:43,587][__main__][INFO] - New best model saved with val acc: 84.84%
[2025-05-27 20:57:36,987][__main__][INFO] - Epoch 37 - Breakpoint: 1980.42 Hz, Transition Width: 60.82
[2025-05-27 20:57:36,988][__main__][INFO] - Epoch 37/50
[2025-05-27 20:57:36,988][__main__][INFO] - Train Loss: 0.4096, Train Acc: 86.81%
[2025-05-27 20:57:36,988][__main__][INFO] - Val Loss: 0.4665, Val Acc: 86.03%
[2025-05-27 20:57:36,988][__main__][INFO] - Val Precision (w): 0.8617, Val Recall (w): 0.8603, Val F1 (w): 0.8603
[2025-05-27 20:57:36,988][__main__][INFO] - Learning Rate: 0.000250
[2025-05-27 20:57:37,023][__main__][INFO] - Validation loss improved from 0.4675 to 0.4665
[2025-05-27 20:57:37,023][__main__][INFO] - New best model saved with val acc: 86.03%
[2025-05-27 21:07:38,609][__main__][INFO] - Epoch 38 - Breakpoint: 1972.49 Hz, Transition Width: 61.33
[2025-05-27 21:07:38,609][__main__][INFO] - Epoch 38/50
[2025-05-27 21:07:38,610][__main__][INFO] - Train Loss: 0.4061, Train Acc: 86.85%
[2025-05-27 21:07:38,610][__main__][INFO] - Val Loss: 0.4803, Val Acc: 84.54%
[2025-05-27 21:07:38,610][__main__][INFO] - Val Precision (w): 0.8469, Val Recall (w): 0.8454, Val F1 (w): 0.8450
[2025-05-27 21:07:38,610][__main__][INFO] - Learning Rate: 0.000250
[2025-05-27 21:07:38,610][__main__][INFO] - No improvement in validation loss for 1/10 epochs
[2025-05-27 21:17:44,262][__main__][INFO] - Epoch 39 - Breakpoint: 1961.79 Hz, Transition Width: 61.63
[2025-05-27 21:17:44,262][__main__][INFO] - Epoch 39/50
[2025-05-27 21:17:44,262][__main__][INFO] - Train Loss: 0.4043, Train Acc: 86.66%
[2025-05-27 21:17:44,262][__main__][INFO] - Val Loss: 0.4910, Val Acc: 85.32%
[2025-05-27 21:17:44,262][__main__][INFO] - Val Precision (w): 0.8550, Val Recall (w): 0.8532, Val F1 (w): 0.8520
[2025-05-27 21:17:44,262][__main__][INFO] - Learning Rate: 0.000250
[2025-05-27 21:17:44,262][__main__][INFO] - No improvement in validation loss for 2/10 epochs
[2025-05-27 21:27:40,189][__main__][INFO] - Epoch 40 - Breakpoint: 1960.92 Hz, Transition Width: 62.17
[2025-05-27 21:27:40,189][__main__][INFO] - Epoch 40/50
[2025-05-27 21:27:40,189][__main__][INFO] - Train Loss: 0.3887, Train Acc: 87.58%
[2025-05-27 21:27:40,189][__main__][INFO] - Val Loss: 0.4561, Val Acc: 85.91%
[2025-05-27 21:27:40,189][__main__][INFO] - Val Precision (w): 0.8609, Val Recall (w): 0.8591, Val F1 (w): 0.8587
[2025-05-27 21:27:40,189][__main__][INFO] - Learning Rate: 0.000250
[2025-05-27 21:27:40,226][__main__][INFO] - Validation loss improved from 0.4571 to 0.4561
[2025-05-27 21:27:40,226][__main__][INFO] - New best model saved with val acc: 85.91%
[2025-05-27 21:37:45,378][__main__][INFO] - Epoch 41 - Breakpoint: 1962.44 Hz, Transition Width: 62.91
[2025-05-27 21:37:45,379][__main__][INFO] - Epoch 41/50
[2025-05-27 21:37:45,379][__main__][INFO] - Train Loss: 0.3790, Train Acc: 87.63%
[2025-05-27 21:37:45,379][__main__][INFO] - Val Loss: 0.4533, Val Acc: 85.67%
[2025-05-27 21:37:45,379][__main__][INFO] - Val Precision (w): 0.8574, Val Recall (w): 0.8567, Val F1 (w): 0.8564
[2025-05-27 21:37:45,379][__main__][INFO] - Learning Rate: 0.000250
[2025-05-27 21:37:45,411][__main__][INFO] - Validation loss improved from 0.4543 to 0.4533
[2025-05-27 21:37:45,411][__main__][INFO] - New best model saved with val acc: 85.67%
[2025-05-27 21:47:56,971][__main__][INFO] - Epoch 42 - Breakpoint: 1960.07 Hz, Transition Width: 63.17
[2025-05-27 21:47:56,972][__main__][INFO] - Epoch 42/50
[2025-05-27 21:47:56,972][__main__][INFO] - Train Loss: 0.3927, Train Acc: 87.61%
[2025-05-27 21:47:56,972][__main__][INFO] - Val Loss: 0.4684, Val Acc: 85.61%
[2025-05-27 21:47:56,972][__main__][INFO] - Val Precision (w): 0.8564, Val Recall (w): 0.8561, Val F1 (w): 0.8559
[2025-05-27 21:47:56,972][__main__][INFO] - Learning Rate: 0.000250
[2025-05-27 21:47:56,973][__main__][INFO] - No improvement in validation loss for 1/10 epochs
[2025-05-27 21:58:08,508][__main__][INFO] - Epoch 43 - Breakpoint: 1955.94 Hz, Transition Width: 63.25
[2025-05-27 21:58:08,509][__main__][INFO] - Epoch 43/50
[2025-05-27 21:58:08,509][__main__][INFO] - Train Loss: 0.3859, Train Acc: 86.94%
[2025-05-27 21:58:08,509][__main__][INFO] - Val Loss: 0.4984, Val Acc: 84.42%
[2025-05-27 21:58:08,509][__main__][INFO] - Val Precision (w): 0.8440, Val Recall (w): 0.8442, Val F1 (w): 0.8429
[2025-05-27 21:58:08,509][__main__][INFO] - Learning Rate: 0.000250
[2025-05-27 21:58:08,510][__main__][INFO] - No improvement in validation loss for 2/10 epochs
[2025-05-27 22:08:05,132][__main__][INFO] - Epoch 44 - Breakpoint: 1953.99 Hz, Transition Width: 63.71
[2025-05-27 22:08:05,132][__main__][INFO] - Epoch 44/50
[2025-05-27 22:08:05,133][__main__][INFO] - Train Loss: 0.3880, Train Acc: 87.18%
[2025-05-27 22:08:05,133][__main__][INFO] - Val Loss: 0.4657, Val Acc: 85.97%
[2025-05-27 22:08:05,133][__main__][INFO] - Val Precision (w): 0.8609, Val Recall (w): 0.8597, Val F1 (w): 0.8594
[2025-05-27 22:08:05,133][__main__][INFO] - Learning Rate: 0.000250
[2025-05-27 22:08:05,164][__main__][INFO] - New best model saved with val acc: 85.97% (val_loss: 0.4657)
[2025-05-27 22:08:05,164][__main__][INFO] - No improvement in validation loss for 3/10 epochs
[2025-05-27 22:18:01,236][__main__][INFO] - Epoch 45 - Breakpoint: 1941.04 Hz, Transition Width: 64.05
[2025-05-27 22:18:01,236][__main__][INFO] - Epoch 45/50
[2025-05-27 22:18:01,236][__main__][INFO] - Train Loss: 0.3737, Train Acc: 87.72%
[2025-05-27 22:18:01,236][__main__][INFO] - Val Loss: 0.4396, Val Acc: 85.97%
[2025-05-27 22:18:01,237][__main__][INFO] - Val Precision (w): 0.8617, Val Recall (w): 0.8597, Val F1 (w): 0.8601
[2025-05-27 22:18:01,237][__main__][INFO] - Learning Rate: 0.000250
[2025-05-27 22:18:01,265][__main__][INFO] - Validation loss improved from 0.4406 to 0.4396
[2025-05-27 22:18:01,265][__main__][INFO] - New best model saved with val acc: 85.97%
[2025-05-27 22:27:55,203][__main__][INFO] - Epoch 46 - Breakpoint: 1937.00 Hz, Transition Width: 63.93
[2025-05-27 22:27:55,203][__main__][INFO] - Epoch 46/50
[2025-05-27 22:27:55,203][__main__][INFO] - Train Loss: 0.3849, Train Acc: 87.51%
[2025-05-27 22:27:55,203][__main__][INFO] - Val Loss: 0.4560, Val Acc: 86.21%
[2025-05-27 22:27:55,203][__main__][INFO] - Val Precision (w): 0.8618, Val Recall (w): 0.8621, Val F1 (w): 0.8611
[2025-05-27 22:27:55,203][__main__][INFO] - Learning Rate: 0.000250
[2025-05-27 22:27:55,231][__main__][INFO] - New best model saved with val acc: 86.21% (val_loss: 0.4560)
[2025-05-27 22:27:55,232][__main__][INFO] - No improvement in validation loss for 1/10 epochs
[2025-05-27 22:38:01,830][__main__][INFO] - Epoch 47 - Breakpoint: 1921.40 Hz, Transition Width: 63.84
[2025-05-27 22:38:01,831][__main__][INFO] - Epoch 47/50
[2025-05-27 22:38:01,831][__main__][INFO] - Train Loss: 0.3974, Train Acc: 87.16%
[2025-05-27 22:38:01,831][__main__][INFO] - Val Loss: 0.4466, Val Acc: 86.03%
[2025-05-27 22:38:01,831][__main__][INFO] - Val Precision (w): 0.8604, Val Recall (w): 0.8603, Val F1 (w): 0.8600
[2025-05-27 22:38:01,831][__main__][INFO] - Learning Rate: 0.000250
[2025-05-27 22:38:01,832][__main__][INFO] - No improvement in validation loss for 2/10 epochs
[2025-05-27 22:47:48,469][__main__][INFO] - Epoch 48 - Breakpoint: 1928.95 Hz, Transition Width: 64.80
[2025-05-27 22:47:48,470][__main__][INFO] - Epoch 48/50
[2025-05-27 22:47:48,470][__main__][INFO] - Train Loss: 0.3843, Train Acc: 87.21%
[2025-05-27 22:47:48,470][__main__][INFO] - Val Loss: 0.4717, Val Acc: 85.32%
[2025-05-27 22:47:48,470][__main__][INFO] - Val Precision (w): 0.8569, Val Recall (w): 0.8532, Val F1 (w): 0.8539
[2025-05-27 22:47:48,470][__main__][INFO] - Learning Rate: 0.000250
[2025-05-27 22:47:48,470][__main__][INFO] - No improvement in validation loss for 3/10 epochs
[2025-05-27 22:57:40,862][__main__][INFO] - Epoch 49 - Breakpoint: 1915.35 Hz, Transition Width: 65.48
[2025-05-27 22:57:40,862][__main__][INFO] - Epoch 49/50
[2025-05-27 22:57:40,862][__main__][INFO] - Train Loss: 0.3869, Train Acc: 87.44%
[2025-05-27 22:57:40,862][__main__][INFO] - Val Loss: 0.4512, Val Acc: 85.85%
[2025-05-27 22:57:40,863][__main__][INFO] - Val Precision (w): 0.8598, Val Recall (w): 0.8585, Val F1 (w): 0.8585
[2025-05-27 22:57:40,863][__main__][INFO] - Learning Rate: 0.000250
[2025-05-27 22:57:40,863][__main__][INFO] - No improvement in validation loss for 4/10 epochs
[2025-05-27 23:07:21,679][__main__][INFO] - Epoch 50 - Breakpoint: 1904.75 Hz, Transition Width: 65.52
[2025-05-27 23:07:21,680][__main__][INFO] - Epoch 50/50
[2025-05-27 23:07:21,680][__main__][INFO] - Train Loss: 0.3677, Train Acc: 88.14%
[2025-05-27 23:07:21,680][__main__][INFO] - Val Loss: 0.4502, Val Acc: 86.03%
[2025-05-27 23:07:21,680][__main__][INFO] - Val Precision (w): 0.8608, Val Recall (w): 0.8603, Val F1 (w): 0.8602
[2025-05-27 23:07:21,681][__main__][INFO] - Learning Rate: 0.000125
[2025-05-27 23:07:21,681][__main__][INFO] - No improvement in validation loss for 5/10 epochs
[2025-05-27 23:07:24,667][__main__][INFO] - Training history plot saved to /app/logs/4birds_CF_combined_log_linear_gru64_50epochs_try2/2025-05-27_14-43-26/training_history.png
[2025-05-27 23:07:24,668][__main__][INFO] - 
Evaluating on test set...
[2025-05-27 23:07:24,752][__main__][INFO] - Loaded best model based on validation loss for testing.
[2025-05-27 23:09:07,042][__main__][INFO] - Test Loss: 0.4438, Test Acc: 86.39%
[2025-05-27 23:09:07,049][__main__][INFO] - Test Precision (w): 0.8664, Test Recall (w): 0.8639, Test F1 (w): 0.8642
[2025-05-27 23:09:07,061][__main__][INFO] - Classification Report (Test Set):
                       precision    recall  f1-score   support

            Bubo_bubo       0.84      0.86      0.85       129
   Certhia_familiaris       0.80      0.88      0.84       198
            Apus_apus       0.95      0.88      0.91       121
Certhia_brachydactyla       0.90      0.82      0.86       209
         Emberiza_cia       0.91      0.85      0.88        60
Lophophanes_cristatus       0.76      0.83      0.79       156
       Periparus_ater       0.86      0.88      0.87       435
     Poecile_montanus       0.83      0.76      0.79       187
             non-bird       0.99      0.97      0.98       187

             accuracy                           0.86      1682
            macro avg       0.87      0.86      0.86      1682
         weighted avg       0.87      0.86      0.86      1682

[2025-05-27 23:09:07,067][__main__][INFO] - Confusion matrix CSV saved to /app/logs/4birds_CF_combined_log_linear_gru64_50epochs_try2/2025-05-27_14-43-26/confusion_matrix.csv
[2025-05-27 23:09:07,660][__main__][INFO] - Confusion matrix PNG saved to /app/logs/4birds_CF_combined_log_linear_gru64_50epochs_try2/2025-05-27_14-43-26/confusion_matrix.png
[2025-05-27 23:09:07,660][__main__][INFO] - Results saved to /app/logs/4birds_CF_combined_log_linear_gru64_50epochs_try2/2025-05-27_14-43-26/results.json
[2025-05-27 23:09:07,661][__main__][INFO] - Model summary saved to /app/logs/4birds_CF_combined_log_linear_gru64_50epochs_try2/2025-05-27_14-43-26/model_summary.txt
[2025-05-27 23:09:07,661][__main__][INFO] - Training completed! Best validation accuracy: 86.21%
[2025-05-27 23:09:07,661][__main__][INFO] - Test accuracy: 86.39%
[2025-05-27 23:09:07,661][__main__][INFO] - Output directory: /app/logs/4birds_CF_combined_log_linear_gru64_50epochs_try2/2025-05-27_14-43-26
