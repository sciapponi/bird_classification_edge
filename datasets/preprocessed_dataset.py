"""
Preprocessed Dataset Loader

Dataset class for loading preprocessed audio files generated by preprocess_dataset.py.
Supports both NPZ and WAV formats with metadata.
"""

import os
import json
import numpy as np
import torch
import torchaudio
from pathlib import Path
from torch.utils.data import Dataset
import logging

logger = logging.getLogger(__name__)

class PreprocessedBirdDataset(Dataset):
    """
    Dataset for loading preprocessed bird audio files.
    
    Supports files preprocessed by preprocess_dataset.py in NPZ or WAV format.
    """
    
    def __init__(self, root_dir, allowed_classes=None, subset="training", 
                 validation_split=0.15, test_split=0.15, split_seed=42,
                 transform=None, return_metadata=False):
        """
        Initialize preprocessed dataset.
        
        Args:
            root_dir: Directory containing preprocessed files organized by species
            allowed_classes: List of species to include (None = all)
            subset: 'training', 'validation', or 'test'
            validation_split: Proportion for validation set
            test_split: Proportion for test set
            split_seed: Random seed for reproducible splits
            transform: Optional transform to apply to audio
            return_metadata: Whether to return metadata dict with audio
        """
        self.root_dir = Path(root_dir)
        self.allowed_classes = allowed_classes
        self.subset = subset
        self.validation_split = validation_split
        self.test_split = test_split
        self.split_seed = split_seed
        self.transform = transform
        self.return_metadata = return_metadata
        
        # Load preprocessing report if available
        self.preprocessing_report = self._load_preprocessing_report()
        
        # Initialize dataset
        self.samples = []
        self.class_to_idx = {}
        self.idx_to_class = {}
        
        self._initialize_dataset()
        
        logger.info(f"PreprocessedBirdDataset initialized:")
        logger.info(f"  Root: {self.root_dir}")
        logger.info(f"  Subset: {self.subset}")
        logger.info(f"  Classes: {len(self.class_to_idx)}")
        logger.info(f"  Samples: {len(self.samples)}")
    
    def _load_preprocessing_report(self):
        """Load preprocessing report if available."""
        report_path = self.root_dir / "preprocessing_report.json"
        if report_path.exists():
            try:
                with open(report_path, 'r') as f:
                    report = json.load(f)
                logger.info(f"Loaded preprocessing report from {report_path}")
                return report
            except Exception as e:
                logger.warning(f"Failed to load preprocessing report: {e}")
        return None
    
    def _initialize_dataset(self):
        """Initialize dataset by finding preprocessed files."""
        np.random.seed(self.split_seed)
        
        # Find all species directories
        species_dirs = [d for d in self.root_dir.iterdir() if d.is_dir()]
        
        # Filter by allowed classes
        if self.allowed_classes:
            species_dirs = [d for d in species_dirs if d.name in self.allowed_classes]
        
        # Create class mappings
        species_names = sorted([d.name for d in species_dirs])
        self.class_to_idx = {name: idx for idx, name in enumerate(species_names)}
        self.idx_to_class = {idx: name for name, idx in self.class_to_idx.items()}
        
        # Collect all files with splits
        for species_dir in species_dirs:
            species_name = species_dir.name
            class_idx = self.class_to_idx[species_name]
            
            # Find preprocessed files (NPZ or WAV)
            files = []
            files.extend(list(species_dir.glob("*.npz")))
            files.extend(list(species_dir.glob("*.wav")))
            
            if not files:
                logger.warning(f"No preprocessed files found in {species_dir}")
                continue
            
            files = sorted(files)
            
            # Split files
            train_files, val_files, test_files = self._split_files(files)
            
            # Select files for current subset
            if self.subset == "training":
                selected_files = train_files
            elif self.subset == "validation":
                selected_files = val_files
            elif self.subset == "test":
                selected_files = test_files
            else:
                raise ValueError(f"Unknown subset: {self.subset}")
            
            # Add to samples
            for file_path in selected_files:
                self.samples.append({
                    'file_path': file_path,
                    'class_name': species_name,
                    'class_idx': class_idx
                })
        
        logger.info(f"Dataset split ({self.subset}):")
        for class_name in species_names:
            class_samples = [s for s in self.samples if s['class_name'] == class_name]
            logger.info(f"  {class_name}: {len(class_samples)} samples")
    
    def _split_files(self, files):
        """Split files into train/validation/test sets."""
        n_files = len(files)
        indices = np.arange(n_files)
        np.random.shuffle(indices)
        
        # Calculate split indices
        test_size = int(n_files * self.test_split)
        val_size = int(n_files * self.validation_split)
        train_size = n_files - test_size - val_size
        
        # Split indices
        train_indices = indices[:train_size]
        val_indices = indices[train_size:train_size + val_size]
        test_indices = indices[train_size + val_size:]
        
        # Get file lists
        train_files = [files[i] for i in train_indices]
        val_files = [files[i] for i in val_indices]
        test_files = [files[i] for i in test_indices]
        
        return train_files, val_files, test_files
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        """
        Get a sample from the dataset.
        
        Returns:
            tuple: (audio_tensor, class_idx) or (audio_tensor, class_idx, metadata)
        """
        sample = self.samples[idx]
        file_path = sample['file_path']
        class_idx = sample['class_idx']
        
        # Load audio data
        audio_tensor, metadata = self._load_preprocessed_file(file_path)
        
        # Apply transform if specified
        if self.transform:
            audio_tensor = self.transform(audio_tensor)
        
        # Return with or without metadata
        if self.return_metadata:
            return audio_tensor, class_idx, metadata
        else:
            return audio_tensor, class_idx
    
    def _load_preprocessed_file(self, file_path):
        """
        Load preprocessed audio file.
        
        Returns:
            tuple: (audio_tensor, metadata)
        """
        file_path = Path(file_path)
        
        try:
            if file_path.suffix == '.npz':
                # Load NPZ file
                data = np.load(file_path, allow_pickle=True)
                audio_data = data['audio']
                metadata = data['metadata'].item() if 'metadata' in data else {}
                
            elif file_path.suffix == '.wav':
                # Load WAV file
                waveform, sr = torchaudio.load(str(file_path))
                audio_data = waveform.squeeze().numpy()
                
                # Load metadata from JSON file
                metadata_path = file_path.with_suffix('.json')
                if metadata_path.exists():
                    with open(metadata_path, 'r') as f:
                        metadata = json.load(f)
                else:
                    metadata = {'sample_rate': sr}
            
            else:
                raise ValueError(f"Unsupported file format: {file_path.suffix}")
            
            # Convert to tensor
            audio_tensor = torch.from_numpy(audio_data).float()
            
            # Ensure correct shape [channels, samples]
            if audio_tensor.dim() == 1:
                audio_tensor = audio_tensor.unsqueeze(0)
            
            return audio_tensor, metadata
            
        except Exception as e:
            logger.error(f"Failed to load {file_path}: {e}")
            # Return silence as fallback
            fallback_length = 96000  # 3 seconds at 32kHz
            audio_tensor = torch.zeros(1, fallback_length)
            metadata = {'error': str(e)}
            return audio_tensor, metadata
    
    def get_class_weights(self):
        """Calculate class weights for balanced training."""
        class_counts = {}
        for sample in self.samples:
            class_name = sample['class_name']
            class_counts[class_name] = class_counts.get(class_name, 0) + 1
        
        total_samples = len(self.samples)
        num_classes = len(self.class_to_idx)
        
        weights = []
        for class_idx in range(num_classes):
            class_name = self.idx_to_class[class_idx]
            class_count = class_counts.get(class_name, 1)
            weight = total_samples / (num_classes * class_count)
            weights.append(weight)
        
        return torch.tensor(weights, dtype=torch.float32)
    
    def get_dataset_info(self):
        """Get dataset information."""
        info = {
            'num_classes': len(self.class_to_idx),
            'num_samples': len(self.samples),
            'class_to_idx': self.class_to_idx,
            'idx_to_class': self.idx_to_class,
            'subset': self.subset,
            'preprocessing_report': self.preprocessing_report
        }
        
        # Add class distribution
        class_distribution = {}
        for sample in self.samples:
            class_name = sample['class_name']
            class_distribution[class_name] = class_distribution.get(class_name, 0) + 1
        
        info['class_distribution'] = class_distribution
        
        return info


def create_preprocessed_dataloader(root_dir, subset="training", batch_size=32, 
                                 num_workers=4, shuffle=None, **dataset_kwargs):
    """
    Create a DataLoader for preprocessed dataset.
    
    Args:
        root_dir: Root directory of preprocessed dataset
        subset: 'training', 'validation', or 'test'
        batch_size: Batch size
        num_workers: Number of worker processes
        shuffle: Whether to shuffle (None = auto based on subset)
        **dataset_kwargs: Additional arguments for PreprocessedBirdDataset
        
    Returns:
        DataLoader: Configured data loader
    """
    from torch.utils.data import DataLoader
    
    # Auto-determine shuffle
    if shuffle is None:
        shuffle = (subset == "training")
    
    # Create dataset
    dataset = PreprocessedBirdDataset(root_dir, subset=subset, **dataset_kwargs)
    
    # Create dataloader
    dataloader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        num_workers=num_workers,
        pin_memory=torch.cuda.is_available()
    )
    
    return dataloader


# Example usage and testing
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Test preprocessed dataset loader")
    parser.add_argument("dataset_dir", help="Directory containing preprocessed dataset")
    parser.add_argument("--subset", default="training", choices=["training", "validation", "test"])
    parser.add_argument("--batch-size", type=int, default=4)
    parser.add_argument("--num-samples", type=int, default=10, help="Number of samples to test")
    
    args = parser.parse_args()
    
    # Test dataset
    print("Testing PreprocessedBirdDataset...")
    
    dataset = PreprocessedBirdDataset(
        args.dataset_dir, 
        subset=args.subset,
        return_metadata=True
    )
    
    print(f"\nDataset Info:")
    info = dataset.get_dataset_info()
    for key, value in info.items():
        if key != 'preprocessing_report':
            print(f"  {key}: {value}")
    
    print(f"\nTesting {args.num_samples} samples:")
    for i in range(min(args.num_samples, len(dataset))):
        audio, label, metadata = dataset[i]
        class_name = dataset.idx_to_class[label]
        print(f"  Sample {i}: {class_name} - Shape: {audio.shape}")
        if 'processing_method' in metadata:
            print(f"    Processing: {metadata['processing_method']}")
    
    # Test dataloader
    print(f"\nTesting DataLoader (batch_size={args.batch_size}):")
    dataloader = create_preprocessed_dataloader(
        args.dataset_dir,
        subset=args.subset,
        batch_size=args.batch_size,
        num_workers=0  # Use 0 for testing
    )
    
    for batch_idx, (audio_batch, label_batch) in enumerate(dataloader):
        print(f"  Batch {batch_idx}: Audio shape: {audio_batch.shape}, Labels: {label_batch}")
        if batch_idx >= 2:  # Test only first few batches
            break
    
    print("âœ… Test completed successfully!") 