# ğŸ¦ Bird Classification Benchmark System

Sistema completo per confrontare le prestazioni del tuo modello di classificazione degli uccelli con BirdNET come riferimento.

## ğŸš€ Quick Start

```bash
# Dal directory root del progetto
cd benchmark
source ../venv/bin/activate
python run_benchmark.py --config-name=quick_start
```

## ğŸ¯ Cosa fa il Sistema

Il benchmark esegue automaticamente questi passi:

1. **ğŸ“ Audio Discovery**: Scopre tutti i file audio dal dataset esistente
2. **ğŸ¤– Student Model Predictions**: Genera predizioni con il tuo modello addestrato
3. **ğŸ¦… BirdNET Predictions**: Genera predizioni con BirdNET come riferimento
4. **ğŸ“Š Model Comparison**: Confronta le prestazioni con metriche dettagliate

## ğŸ“Š Output e Risultati

Tutti i risultati vengono salvati in `benchmark/benchmark_results/`:

```
benchmark_results/
â”œâ”€â”€ predictions/
â”‚   â”œâ”€â”€ ground_truth.csv          # Ground truth auto-generato
â”‚   â”œâ”€â”€ student_predictions.csv   # Predizioni del tuo modello
â”‚   â””â”€â”€ birdnet_predictions.csv   # Predizioni di BirdNET
â””â”€â”€ comparison/
    â”œâ”€â”€ comparison_report.txt      # Report dettagliato
    â”œâ”€â”€ detailed_results.json     # Metriche complete
    â”œâ”€â”€ confusion_matrices.png    # Matrici di confusione
    â”œâ”€â”€ agreement_analysis.png    # Analisi di accordo tra modelli
    â””â”€â”€ per_class_accuracy.png    # Accuratezza per classe
```

## âš™ï¸ Configurazione

### Quick Start (consigliato)
```yaml
# config/quick_start.yaml
benchmark:
  paths:
    audio_dir: "bird_sound_dataset"
    student_model: "best_distillation_model.pt"
    student_config: "config/bird_classification.yaml"
    output_dir: "benchmark_results"
```

### Configurazione Completa
```yaml
# config/benchmark.yaml - Configurazione avanzata con tutti i parametri
```

## ğŸ› ï¸ Componenti del Sistema

### 1. Audio Discovery (`run_benchmark.py`)
- Scansiona automaticamente `bird_sound_dataset/` e `augmented_dataset/no_birds/`
- Genera ground truth dalla struttura delle cartelle
- Nessuna duplicazione o preprocessing aggiuntivo

### 2. Student Model Predictor (`predict_student.py`)
- Carica il modello addestrato (`Improved_Phi_GRU_ATT`)
- Preprocessing audio identico al training
- Progress bar durante le predizioni

### 3. BirdNET Predictor (`predict_birdnet.py`)
- Filtra automaticamente per le specie del progetto
- Usa file temporaneo per species filtering
- Cleanup automatico delle risorse

### 4. Model Comparator (`compare_predictions.py`)
- Metriche complete: accuracy, precision, recall, F1-score
- Matrici di confusione per entrambi i modelli
- Analisi di accordo/disaccordo tra modelli
- Accuratezza per classe
- Report dettagliato in formato testo

## ğŸ“ˆ Metriche Calcolate

- **Overall Accuracy**: Accuratezza complessiva
- **Per-Class Metrics**: Precision, recall, F1 per ogni specie
- **Confusion Matrices**: Visualizzazione errori di classificazione
- **Agreement Analysis**: 
  - Entrambi corretti
  - Solo student corretto
  - Solo BirdNET corretto
  - Entrambi sbagliati
- **Confidence Analysis**: Distribuzione delle confidenze

## ğŸ”§ Personalizzazione

### Aggiungere Nuove Specie
1. Aggiorna `config/bird_classification.yaml`
2. Assicurati che BirdNET supporti le specie
3. Ri-addestra il modello se necessario

### Modificare Soglie di Confidenza
```yaml
student_model:
  inference:
    confidence_threshold: 0.1

birdnet:
  confidence_threshold: 0.1
```

### Cambiare Output Format
```yaml
comparison:
  save_plots: true
  save_detailed_json: true
  save_confusion_matrices: true
```

## ğŸ› Troubleshooting

### Errori Comuni

**"No audio files found"**
- Verifica che `bird_sound_dataset/` esista
- Controlla i formati supportati (.wav, .mp3, .flac)

**"Model loading failed"**
- Verifica il path del modello in `quick_start.yaml`
- Controlla compatibilitÃ  architettura modello

**"BirdNET species not found"**
- Alcune specie potrebbero non essere in BirdNET
- Controlla la lista supportata online

### Performance Tips

- Usa `files_limit: 100` in fase di test
- BirdNET Ã¨ piÃ¹ lento, considera subset per test rapidi
- I risultati vengono cachati per evitare ricalcoli

## ğŸ“ Log e Debug

I log dettagliati vengono salvati automaticamente da Hydra:
```
benchmark_results/hydra_outputs/[timestamp]/
â”œâ”€â”€ main.log           # Log completo
â”œâ”€â”€ .hydra/
â”‚   â”œâ”€â”€ config.yaml    # Configurazione usata
â”‚   â””â”€â”€ overrides.yaml # Override applicati
```

## ğŸ¤ Contribuire

Per migliorare il sistema:
1. Aggiungi nuove metriche in `compare_predictions.py`
2. Implementa nuovi visualizzazioni
3. Ottimizza preprocessing per velocitÃ 
4. Aggiungi supporto per nuovi modelli di riferimento 